{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv\n",
    "import random  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crteat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_Data_Mask = []\n",
    "list_Data_Nomask = []\n",
    "\n",
    "#使用列表记录图像的路径、特征和target\n",
    "for i in os.listdir('CMFD'):\n",
    "    for j in os.listdir(f'CMFD/{i}'):    #遍历CMFD\n",
    "        list_Data_Mask.append((f'CMFD/{i}/{j}',j[6:10],0))     #加入列表，元素的是图片存储地址\n",
    "#print(CMFD)\n",
    "\n",
    "for i in os.listdir('IMFD'):\n",
    "    for j in os.listdir(f'IMFD/{i}'):    #遍历IMFD\n",
    "        if (j[6:-4]=='Mask_Mouth_Chin'):\n",
    "            list_Data_Nomask.append((f'IMFD/{i}/{j}',j[6:-4],1))\n",
    "        elif  (j[6:-4]=='Mask_Nose_Mouth'):\n",
    "            list_Data_Nomask.append((f'IMFD/{i}/{j}',j[6:-4],2))\n",
    "        elif  (j[6:-4]=='Mask_Chin'):\n",
    "            list_Data_Nomask.append((f'IMFD/{i}/{j}',j[6:-4],3))   #加入列表，元素的是图片存储地址\n",
    "#print(CMFD)\n",
    "\n",
    "for i in os.listdir('NMFD'):\n",
    "    for j in os.listdir(f'NMFD/{i}'):    #遍历NMFD\n",
    "        list_Data_Nomask.append((f'NMFD/{i}/{j}','NoMask',4))     #将没戴口罩的图片也存入列表中\n",
    "#print(CMFD)\n",
    "\n",
    "list_Train_Mask,list_Test_Mask = train_test_split(list_Data_Mask,train_size=0.1,random_state=12)\n",
    "\n",
    "list_Train_Nomask,list_Test_Nomask = train_test_split(list_Data_Nomask,train_size=0.1,random_state=12)\n",
    "\n",
    "list_Train = list_Train_Mask + list_Train_Nomask\n",
    "list_Test = list_Test_Mask + list_Test_Nomask\n",
    "\n",
    "#创建DataFrame\n",
    "df_Train = pd.DataFrame(list_Train,columns=['Addr','Feature','Target'])\n",
    "df_Test = pd.DataFrame(list_Test,columns=['Addr','Feature','Target'])\n",
    "#print(df_NOMASK)\n",
    "\n",
    "\n",
    "\n",
    "#将DataFrame转换为.csv文件，方便在DataSet中读取和操作\n",
    "#print(df_Data)\n",
    "df_Train.to_csv('train.csv')\n",
    "df_Test.to_csv('test.csv')\n",
    "\n",
    "#重写DataSet类，特别是其中的__len__和__getitem__方法\n",
    "class MaskDataSet(Dataset):\n",
    "    def __init__(self,path):\n",
    "        #self.path = path\n",
    "        self.labels = pd.read_csv(path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_nparr = plt.imread(self.labels.iloc[index,1])  #这里返回tensor型1024x1024x3(H,W,C)的图像\n",
    "        img_chw = np.transpose(img_nparr)         #此处进行转换\n",
    "        img = torch.FloatTensor(img_chw)\n",
    "        tar = torch.tensor([self.labels.iloc[index,3]])\n",
    "        return img,tar                       #这里返回tensor型3x1024x1024(C,H,W)的图像数据和对应的target\n",
    "\n",
    "#实例化戴口罩和未正确戴口罩的数据集，并使用重载的‘+’进行拼接，得到训练集\n",
    "#使用时只需要使用DataLoader进行数据载入即可\n",
    "#dataset_Data[i]由两个tensor，一个是1024x1024x3的像素数据，紧接着是该图像对应的Target值\n",
    "dataset_Train = MaskDataSet('train.csv')\n",
    "dataset_Test = MaskDataSet('test.csv')\n",
    "###以上部分验证无误\n",
    "#print(dataset_Data[0])\n",
    "\n",
    "###\n",
    "dataload_Data_train = DataLoader(dataset_Train,3)   #此处确定一个超参数batch_size ,由于本机GPU内存太小，只能接受3个图像\n",
    "dataload_Data_test = DataLoader(dataset_Test,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MASKmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MASKmodel,self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "       \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels = 30,kernel_size = 4,stride = 1,groups=1),  #这里输入的图像数据要是（C,H,W）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,4)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=30,out_channels = 100,kernel_size = 4,stride = 1,groups=1),  #这里输入的图像数据要是（C,H,W）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,4)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=100,out_channels = 300,kernel_size = 4,stride = 1,groups=1),  #这里输入的图像数据要是（C,H,W）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,4)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=300,out_channels = 500,kernel_size = 4,stride = 1,groups=1),  #这里输入的图像数据要是（C,H,W）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,4)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(500*3*3,500)\n",
    "\n",
    "        self.fc2 = nn.Linear(500,120)\n",
    "\n",
    "        self.fc3 = nn.Linear(120,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x = self.flatten(x)\n",
    "        ###卷积\n",
    "        x=self.conv1(x)       #size:3x30x254x254\n",
    "        x=self.conv2(x)       #size:3x100x62x62\n",
    "        x=self.conv3(x)       #size:3x300x15x15\n",
    "        x=self.conv4(x)       #size:3x500x3x3\n",
    "        ###全连接\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x,1)\n",
    "        return  x             #size:\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASKmodel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 30, kernel_size=(9, 9), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(30, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(100, 300, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=110, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=10, out_features=5, bias=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=67500, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = MASKmodel()\n",
    "model.to(device)\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)  #这里使用梯度下降确定一个超参数：learning_rate\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_epochs = 5\n",
    "with torch.no_grad():\n",
    " for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    print(\"Epoch {}/{}\".format(epoch,n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for batchs,(X,y) in enumerate(dataload_Data_train):   ###数据的batch数量存在问题，设置的是1，但是实际太多了\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(X)\n",
    "        _,pred=torch.max(outputs.data,1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = cost(outputs,y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "        running_correct += torch.sum(pred == y)\n",
    "    testing_correct = 0\n",
    "    for data in dataload_Data_test:\n",
    "        outputs = model(X)\n",
    "        _,pred=torch.max(outputs.data,1)\n",
    "        testing_correct += torch.sum(pred == y)\n",
    "    print(\"Loss is:{:4f},Train Accuracy is:{:.4f}%,Test Accuracy is:{:.4f}\".format(running_loss/len(dataload_Data_train),100*running_correct/len(dataload_Data_train)\n",
    "                                                                                  ,100*testing_correct/len(dataload_Data_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
